{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "# embed static images in the ipynb\n",
    "%matplotlib inline \n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pytorch_lightning as pl \n",
    "# ! pip install pytorch-lightning --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(pl.LightningModule):\n",
    "    # ----------------------------------\n",
    "    # Network Architecture\n",
    "    # ----------------------------------\n",
    "    def __init__(self, data_dir: str, lr: float = 1e-2):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Hard-coded constants\n",
    "        self.BATCH_SIZE = 65\n",
    "        self.n_classes = 10\n",
    "        self.dims = (1, 28, 28)\n",
    "        self.loss_fn = F.nll_loss\n",
    "        channels, width, height = self.dims\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, 64),\n",
    "                nn.Dropout(p = 0.2),\n",
    "                nn.LeakyReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(p = 0.4),\n",
    "            nn.Linear(32, self.n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_layers(x)\n",
    "        return F.log_softmax(input = x, dim = 1)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Training, validation, and test steps\n",
    "    # ----------------------------------\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x) \n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # compute loss\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        # compute accuracy\n",
    "        y_hat = self.predict(x)\n",
    "        accuracy = self.accuracy(y_hat, y)\n",
    "        # self.log interacts with TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def predict(self, x):\n",
    "        logits = self(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, y_hat, y):\n",
    "        return pl.metrics.functional.accuracy(y_hat, y)\n",
    "        \n",
    "    # ----------------------------------\n",
    "    # Data preparation hooks\n",
    "    # ----------------------------------\n",
    "    def train_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        dl = torch.utils.data.DataLoader(\n",
    "            self.train_set, self.BATCH_SIZE)\n",
    "        return dl\n",
    "    def val_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        dl = torch.utils.data.DataLoader(\n",
    "            self.val_set, self.BATCH_SIZE)\n",
    "        return dl\n",
    "    def test_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        dl = torch.utils.data.DataLoader(\n",
    "            self.test_set, self.BATCH_SIZE)\n",
    "        return dl\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage in ['fit', None]:\n",
    "            train_data = torchvision.datasets.MNIST(\n",
    "                os.getcwd(), train=True, download=True, \n",
    "                transform = torchvision.transforms.ToTensor()\n",
    "            )\n",
    "            splits = np.array([15, 70]) / 85 * len(train_data)\n",
    "            splits = splits.astype(int)\n",
    "            splits[-1] += len(train_data) - splits.sum() \n",
    "            train_val_set = torch.utils.data.random_split(\n",
    "                dataset = train_data,\n",
    "                lengths = splits)\n",
    "            self.train_set, self.val_set = train_val_set\n",
    "        if stage in ['test', None]:\n",
    "            test_set = torch.vision.datasets(\n",
    "                os.getcwd(), train=False, download=False,\n",
    "                transform = torchvision.transforms.ToTensor()\n",
    "            )\n",
    "            self.test_set = test_set\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | fc_layers | Sequential | 52.6 K\n",
      "-----------------------------------------\n",
      "52.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.6 K    Total params\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "\n",
    "model = LitMNIST(data_dir = os.path.join(os.getcwd(), \"temp\"))\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=3, \n",
    "                     progress_bar_refresh_rate=0)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "source": [
    "Why is it called logits in `training_step`?\n",
    "> \"Logits are interpreted to be the unnormalised (or not-yet normalised) predictions (or outputs) of a model. These can give results, but we don't normally stop with logits, because interpreting their raw values is not easy...  \n",
    "The layers of a neural network commonly take input data, multiply that by some parameters (weights) that we want to learn, then apply a non-linearity function, which provides the model with the power to learn non-linear relationships.\" - [source]\n",
    "\n",
    "[source]: https://datascience.stackexchange.com/questions/31041/what-does-logits-in-machine-learning-mean"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\uniqu\\\\Adaptation\\\\github repos\\\\Bioinformatics-Neural Networks for Genomic Risk\\\\temp'"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "type(os.path.join(os.getcwd(), \"data\"))"
   ]
  }
 ]
}